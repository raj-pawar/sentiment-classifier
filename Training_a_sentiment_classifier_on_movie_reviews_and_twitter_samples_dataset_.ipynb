{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "Training a sentiment classifier on movie_reviews and twitter_samples dataset .ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUNSQouO04Zl"
      },
      "source": [
        "# Sentiment Classifier for movie_reviews and twitter_samples dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2hQWpyv04Zn"
      },
      "source": [
        "### I have used the bag of words method to train the classifiers where a particular number of words in the datasets have been created into features for each instance containing a True/False value to indicate the presence/absense of words in it. I chose 3000 words for most of the classifiers after removing stop words and punctuations. Further, I tried to increase accuracy of classifiers by considering 3000 most common words for creating features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vv8QyacT04Zo"
      },
      "source": [
        "import nltk\n",
        "import random\n",
        "from nltk.corpus import movie_reviews\n",
        "from nltk.classify.scikitlearn import SklearnClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from nltk.classify import ClassifierI\n",
        "from statistics import mode\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSNryxO604Zu"
      },
      "source": [
        "## movie_reviews Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiFMpsD204Zv"
      },
      "source": [
        "###### Storing reviews in a list as a list of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMKGPa8U04Zw"
      },
      "source": [
        "reviews = [(list(movie_reviews.words(fileid)), category)\n",
        "            for category in movie_reviews.categories()\n",
        "            for fileid in movie_reviews.fileids(category)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9pUrHRD04Z2",
        "outputId": "c1545b84-c2c2-4516-e3af-0bcc77ea65d7"
      },
      "source": [
        "print(\"First Review\")\n",
        "print(reviews[0])\n",
        "print(\"\\n\\n\")\n",
        "print(\"Last Review\")\n",
        "print(reviews[1999])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Review\n",
            "(['plot', ':', 'two', 'teen', 'couples', 'go', 'to', 'a', 'church', 'party', ',', 'drink', 'and', 'then', 'drive', '.', 'they', 'get', 'into', 'an', 'accident', '.', 'one', 'of', 'the', 'guys', 'dies', ',', 'but', 'his', 'girlfriend', 'continues', 'to', 'see', 'him', 'in', 'her', 'life', ',', 'and', 'has', 'nightmares', '.', 'what', \"'\", 's', 'the', 'deal', '?', 'watch', 'the', 'movie', 'and', '\"', 'sorta', '\"', 'find', 'out', '.', '.', '.', 'critique', ':', 'a', 'mind', '-', 'fuck', 'movie', 'for', 'the', 'teen', 'generation', 'that', 'touches', 'on', 'a', 'very', 'cool', 'idea', ',', 'but', 'presents', 'it', 'in', 'a', 'very', 'bad', 'package', '.', 'which', 'is', 'what', 'makes', 'this', 'review', 'an', 'even', 'harder', 'one', 'to', 'write', ',', 'since', 'i', 'generally', 'applaud', 'films', 'which', 'attempt', 'to', 'break', 'the', 'mold', ',', 'mess', 'with', 'your', 'head', 'and', 'such', '(', 'lost', 'highway', '&', 'memento', ')', ',', 'but', 'there', 'are', 'good', 'and', 'bad', 'ways', 'of', 'making', 'all', 'types', 'of', 'films', ',', 'and', 'these', 'folks', 'just', 'didn', \"'\", 't', 'snag', 'this', 'one', 'correctly', '.', 'they', 'seem', 'to', 'have', 'taken', 'this', 'pretty', 'neat', 'concept', ',', 'but', 'executed', 'it', 'terribly', '.', 'so', 'what', 'are', 'the', 'problems', 'with', 'the', 'movie', '?', 'well', ',', 'its', 'main', 'problem', 'is', 'that', 'it', \"'\", 's', 'simply', 'too', 'jumbled', '.', 'it', 'starts', 'off', '\"', 'normal', '\"', 'but', 'then', 'downshifts', 'into', 'this', '\"', 'fantasy', '\"', 'world', 'in', 'which', 'you', ',', 'as', 'an', 'audience', 'member', ',', 'have', 'no', 'idea', 'what', \"'\", 's', 'going', 'on', '.', 'there', 'are', 'dreams', ',', 'there', 'are', 'characters', 'coming', 'back', 'from', 'the', 'dead', ',', 'there', 'are', 'others', 'who', 'look', 'like', 'the', 'dead', ',', 'there', 'are', 'strange', 'apparitions', ',', 'there', 'are', 'disappearances', ',', 'there', 'are', 'a', 'looooot', 'of', 'chase', 'scenes', ',', 'there', 'are', 'tons', 'of', 'weird', 'things', 'that', 'happen', ',', 'and', 'most', 'of', 'it', 'is', 'simply', 'not', 'explained', '.', 'now', 'i', 'personally', 'don', \"'\", 't', 'mind', 'trying', 'to', 'unravel', 'a', 'film', 'every', 'now', 'and', 'then', ',', 'but', 'when', 'all', 'it', 'does', 'is', 'give', 'me', 'the', 'same', 'clue', 'over', 'and', 'over', 'again', ',', 'i', 'get', 'kind', 'of', 'fed', 'up', 'after', 'a', 'while', ',', 'which', 'is', 'this', 'film', \"'\", 's', 'biggest', 'problem', '.', 'it', \"'\", 's', 'obviously', 'got', 'this', 'big', 'secret', 'to', 'hide', ',', 'but', 'it', 'seems', 'to', 'want', 'to', 'hide', 'it', 'completely', 'until', 'its', 'final', 'five', 'minutes', '.', 'and', 'do', 'they', 'make', 'things', 'entertaining', ',', 'thrilling', 'or', 'even', 'engaging', ',', 'in', 'the', 'meantime', '?', 'not', 'really', '.', 'the', 'sad', 'part', 'is', 'that', 'the', 'arrow', 'and', 'i', 'both', 'dig', 'on', 'flicks', 'like', 'this', ',', 'so', 'we', 'actually', 'figured', 'most', 'of', 'it', 'out', 'by', 'the', 'half', '-', 'way', 'point', ',', 'so', 'all', 'of', 'the', 'strangeness', 'after', 'that', 'did', 'start', 'to', 'make', 'a', 'little', 'bit', 'of', 'sense', ',', 'but', 'it', 'still', 'didn', \"'\", 't', 'the', 'make', 'the', 'film', 'all', 'that', 'more', 'entertaining', '.', 'i', 'guess', 'the', 'bottom', 'line', 'with', 'movies', 'like', 'this', 'is', 'that', 'you', 'should', 'always', 'make', 'sure', 'that', 'the', 'audience', 'is', '\"', 'into', 'it', '\"', 'even', 'before', 'they', 'are', 'given', 'the', 'secret', 'password', 'to', 'enter', 'your', 'world', 'of', 'understanding', '.', 'i', 'mean', ',', 'showing', 'melissa', 'sagemiller', 'running', 'away', 'from', 'visions', 'for', 'about', '20', 'minutes', 'throughout', 'the', 'movie', 'is', 'just', 'plain', 'lazy', '!', '!', 'okay', ',', 'we', 'get', 'it', '.', '.', '.', 'there', 'are', 'people', 'chasing', 'her', 'and', 'we', 'don', \"'\", 't', 'know', 'who', 'they', 'are', '.', 'do', 'we', 'really', 'need', 'to', 'see', 'it', 'over', 'and', 'over', 'again', '?', 'how', 'about', 'giving', 'us', 'different', 'scenes', 'offering', 'further', 'insight', 'into', 'all', 'of', 'the', 'strangeness', 'going', 'down', 'in', 'the', 'movie', '?', 'apparently', ',', 'the', 'studio', 'took', 'this', 'film', 'away', 'from', 'its', 'director', 'and', 'chopped', 'it', 'up', 'themselves', ',', 'and', 'it', 'shows', '.', 'there', 'might', \"'\", 've', 'been', 'a', 'pretty', 'decent', 'teen', 'mind', '-', 'fuck', 'movie', 'in', 'here', 'somewhere', ',', 'but', 'i', 'guess', '\"', 'the', 'suits', '\"', 'decided', 'that', 'turning', 'it', 'into', 'a', 'music', 'video', 'with', 'little', 'edge', ',', 'would', 'make', 'more', 'sense', '.', 'the', 'actors', 'are', 'pretty', 'good', 'for', 'the', 'most', 'part', ',', 'although', 'wes', 'bentley', 'just', 'seemed', 'to', 'be', 'playing', 'the', 'exact', 'same', 'character', 'that', 'he', 'did', 'in', 'american', 'beauty', ',', 'only', 'in', 'a', 'new', 'neighborhood', '.', 'but', 'my', 'biggest', 'kudos', 'go', 'out', 'to', 'sagemiller', ',', 'who', 'holds', 'her', 'own', 'throughout', 'the', 'entire', 'film', ',', 'and', 'actually', 'has', 'you', 'feeling', 'her', 'character', \"'\", 's', 'unraveling', '.', 'overall', ',', 'the', 'film', 'doesn', \"'\", 't', 'stick', 'because', 'it', 'doesn', \"'\", 't', 'entertain', ',', 'it', \"'\", 's', 'confusing', ',', 'it', 'rarely', 'excites', 'and', 'it', 'feels', 'pretty', 'redundant', 'for', 'most', 'of', 'its', 'runtime', ',', 'despite', 'a', 'pretty', 'cool', 'ending', 'and', 'explanation', 'to', 'all', 'of', 'the', 'craziness', 'that', 'came', 'before', 'it', '.', 'oh', ',', 'and', 'by', 'the', 'way', ',', 'this', 'is', 'not', 'a', 'horror', 'or', 'teen', 'slasher', 'flick', '.', '.', '.', 'it', \"'\", 's', 'just', 'packaged', 'to', 'look', 'that', 'way', 'because', 'someone', 'is', 'apparently', 'assuming', 'that', 'the', 'genre', 'is', 'still', 'hot', 'with', 'the', 'kids', '.', 'it', 'also', 'wrapped', 'production', 'two', 'years', 'ago', 'and', 'has', 'been', 'sitting', 'on', 'the', 'shelves', 'ever', 'since', '.', 'whatever', '.', '.', '.', 'skip', 'it', '!', 'where', \"'\", 's', 'joblo', 'coming', 'from', '?', 'a', 'nightmare', 'of', 'elm', 'street', '3', '(', '7', '/', '10', ')', '-', 'blair', 'witch', '2', '(', '7', '/', '10', ')', '-', 'the', 'crow', '(', '9', '/', '10', ')', '-', 'the', 'crow', ':', 'salvation', '(', '4', '/', '10', ')', '-', 'lost', 'highway', '(', '10', '/', '10', ')', '-', 'memento', '(', '10', '/', '10', ')', '-', 'the', 'others', '(', '9', '/', '10', ')', '-', 'stir', 'of', 'echoes', '(', '8', '/', '10', ')'], 'neg')\n",
            "\n",
            "\n",
            "\n",
            "Last Review\n",
            "(['truman', '(', '\"', 'true', '-', 'man', '\"', ')', 'burbank', 'is', 'the', 'perfect', 'name', 'for', 'jim', 'carrey', \"'\", 's', 'character', 'in', 'this', 'film', '.', 'president', 'truman', 'was', 'an', 'unassuming', 'man', 'who', 'became', 'known', 'worldwide', ',', 'in', 'spite', 'of', '(', 'or', 'was', 'it', 'because', 'of', ')', 'his', 'stature', '.', '\"', 'truman', '\"', 'also', 'recalls', 'an', 'era', 'of', 'plenty', 'following', 'a', 'grim', 'war', ',', 'an', 'era', 'when', 'planned', 'communities', 'built', 'by', 'government', 'scientists', 'promised', 'an', 'idyllic', 'life', 'for', 'americans', '.', 'and', 'burbank', ',', 'california', ',', 'brings', 'to', 'mind', 'the', 'tonight', 'show', 'and', 'the', 'home', 'of', 'nbc', '.', 'if', 'hollywood', 'is', 'the', 'center', 'of', 'the', 'film', 'world', ',', 'burbank', 'is', ',', 'or', 'was', ',', 'the', 'center', 'of', 'tv', \"'\", 's', 'world', ',', 'the', 'world', 'where', 'our', 'protagonist', 'lives', '.', 'combine', 'all', 'these', 'names', 'and', 'concepts', 'into', '\"', 'truman', 'burbank', ',', '\"', 'and', 'you', 'get', 'something', 'that', 'well', 'describes', 'him', 'and', 'his', 'artificial', 'world', '.', 'truman', 'leads', 'the', 'perfect', 'life', '.', 'his', 'town', ',', 'his', 'car', ',', 'and', 'his', 'wife', 'are', 'picture', 'perfect', '.', 'his', 'idea', 'of', 'reality', 'comes', 'under', 'attack', 'one', 'day', 'when', 'a', 'studio', 'light', 'falls', 'from', 'the', 'sky', '.', 'the', 'radio', 'explains', 'that', 'an', 'overflying', 'airplane', 'started', 'coming', 'apart', '.', '.', '.', 'but', 'then', 'why', 'would', 'an', 'airplane', 'be', 'carrying', 'a', 'studio', 'light', '?', 'the', 'next', 'day', 'during', 'the', 'drive', 'to', 'work', ',', 'the', 'radio', 'jams', 'and', 'he', 'starts', 'picking', 'up', 'a', 'voice', 'that', 'exactly', 'describes', 'his', 'movements', '.', 'he', 'is', 'so', 'distracted', 'that', 'he', 'nearly', 'hits', 'a', 'pedestrian', '.', 'when', 'the', 'radio', 'comes', 'back', 'to', 'normal', ',', 'the', 'announcer', 'warns', 'listeners', 'to', 'drive', 'carefully', '.', 'his', 'suspicion', 'aroused', ',', 'he', 'wanders', 'around', 'the', 'town', 'square', 'looking', 'for', 'other', 'oddities', '.', 'the', 'world', 'appears', 'to', 'be', 'functioning', 'properly', 'until', 'he', 'enters', 'an', 'office', 'building', 'and', 'tries', 'to', 'take', 'the', 'elevator', '.', 'the', 'elevator', 'doors', 'open', 'up', 'on', 'a', 'small', 'lounge', 'with', 'people', 'on', 'coffee', 'breaks', '.', 'a', 'grip', 'sees', 'truman', 'him', 'and', 'quickly', 'moves', 'a', 'paneled', 'door', ',', 'made', 'to', 'look', 'like', 'the', 'back', 'of', 'an', 'elevator', ',', 'into', 'place', '.', 'two', 'security', 'guards', 'grab', 'him', 'and', 'throw', 'him', 'out', '.', 'truman', 'is', 'really', 'suspicious', 'now', '.', 'it', 'gets', 'even', 'worse', 'the', 'next', 'day', 'when', 'his', 'wife', ',', 'a', 'nurse', ',', 'describes', 'an', 'elevator', 'accident', 'in', 'the', 'building', 'where', 'he', 'saw', 'the', 'lounge', '.', '\"', 'it', \"'\", 's', 'best', 'not', 'to', 'think', 'about', 'it', ',', '\"', 'she', 'says', ',', 'trying', 'vainly', 'to', 'change', 'truman', \"'\", 's', 'memory', '.', 'truman', 'becomes', 'determined', 'to', 'see', 'who', 'or', 'what', 'is', 'behind', 'this', 'apparently', 'elaborate', 'hoax', 'at', 'his', 'expense', '.', 'at', 'every', 'turn', 'he', 'is', 'stopped', 'by', 'an', 'amazing', 'coincidence', 'that', 'just', 'happens', 'to', 'keep', 'him', 'in', 'his', 'own', 'little', 'town', '.', 'his', 'last', 'hope', 'is', 'to', 'quell', 'his', 'fear', 'of', 'the', 'ocean', 'and', 'sail', 'to', 'the', 'edge', 'of', 'the', 'world', '.', 'you', 'know', 'by', 'now', 'that', 'truman', \"'\", 's', 'life', 'is', 'the', 'subject', 'of', 'a', 'television', 'program', '.', 'his', 'actions', 'are', '\"', 'real', '\"', 'but', 'everything', 'else', 'is', 'carefully', 'scripted', ',', 'from', 'the', 'death', 'of', 'his', 'father', 'to', 'the', 'choice', 'of', 'his', 'wife', '.', 'truman', 'is', 'determined', 'to', 'find', 'out', 'what', 'the', 'big', 'hoax', 'is', '.', 'meanwhile', ',', 'christof', ',', 'the', 'all', '-', 'seeing', 'creator', 'of', 'truman', \"'\", 's', 'world', 'does', 'his', 'best', 'to', 'keep', 'him', 'unaware', 'and', 'happy', '.', 'it', \"'\", 's', 'sort', 'of', 'like', 'westworld', 'told', 'from', 'the', 'robots', \"'\", 'point', 'of', 'view', ',', 'or', 'jurassic', 'park', 'from', 'the', 'dinosaurs', \"'\", 'point', 'of', 'view', '.', 'we', 'root', 'for', 'the', 'captive', 'of', 'the', 'cage', '-', 'world', '.', 'our', 'protagonist', 'is', 'counting', 'on', '\"', 'chaos', 'theory', '\"', 'to', 'help', 'him', 'escape', 'his', 'elaborate', 'trap', '.', 'the', 'story', ',', 'written', 'by', 'andrew', 'niccol', '(', 'writer', '/', 'director', 'of', 'gattaca', ')', ',', 'introduces', 'some', 'interesting', 'questions', ',', 'such', 'as', 'the', 'ethics', 'of', 'subjecting', 'a', 'person', 'to', 'this', 'type', 'of', 'life', ',', 'or', 'the', 'psychological', 'impact', 'of', 'learning', 'that', 'your', 'entire', 'life', 'has', 'all', 'been', 'fake', '.', 'although', 'these', 'questions', 'came', 'to', 'mind', ',', 'i', 'don', \"'\", 't', 'think', 'the', 'film', 'itself', 'asked', 'them', '.', 'it', 'certainly', 'didn', \"'\", 't', 'address', 'them', 'or', 'try', 'to', 'answer', 'them', '.', 'i', 'was', 'particularly', 'disappointed', 'that', 'the', 'film', 'didn', \"'\", 't', 'deal', 'more', 'with', 'the', 'trauma', 'of', 'learning', 'one', \"'\", 's', 'life', 'is', 'a', 'tv', 'show', '.', 'carrey', \"'\", 's', 'performance', 'at', 'the', 'end', 'showed', 'a', 'smidgen', 'of', 'truman', \"'\", 's', 'pain', ',', 'but', 'i', 'almost', 'felt', 'that', 'he', 'got', 'over', 'it', 'too', 'easily', 'for', 'the', 'sake', 'of', 'the', 'film', \"'\", 's', 'pacing', '.', 'earlier', 'in', 'the', 'movie', 'i', 'found', 'myself', 'wondering', 'if', 'it', 'would', 'be', 'better', 'for', 'truman', 'to', 'find', 'out', 'the', 'truth', 'or', 'whether', 'i', 'should', 'root', 'for', 'him', 'to', 'be', 'well', '.', 'the', 'two', 'seemed', 'exclusive', 'of', 'one', 'another', ',', 'but', 'weir', 'and', 'niccol', 'didn', \"'\", 't', 'see', 'it', 'that', 'way', '.', 'perhaps', 'it', \"'\", 's', 'not', 'fair', 'to', 'criticize', 'a', 'movie', 'for', 'what', 'it', 'isn', \"'\", 't', ',', 'but', 'it', 'seems', 'like', 'there', 'were', 'some', 'missed', 'opportunities', 'here', '.', 'but', 'on', 'its', 'own', 'terms', ',', 'the', 'movie', 'is', 'well', 'made', '.', 'sight', ',', 'sound', 'and', 'pacing', 'are', 'all', 'handled', 'competently', '.', 'much', 'of', 'the', 'first', 'part', 'of', 'the', 'movie', 'is', 'the', 'truman', 'show', '.', 'the', 'scenes', 'are', 'all', 'apparently', 'shot', 'from', 'hidden', 'cameras', ',', 'with', 'snoots', 'and', 'obstructions', 'covering', 'the', 'corners', 'of', 'the', 'screen', '.', 'one', 'hidden', 'camera', 'is', 'apparently', 'in', 'his', 'car', 'radio', ',', 'the', 'green', 'led', 'numbers', 'obscuring', 'the', 'lower', 'part', 'of', 'the', 'screen', '.', 'the', 'music', 'is', 'well', '-', 'chosen', 'and', 'scored', '.', 'the', 'film', 'opens', 'with', 'what', 'sounds', 'like', 'family', 'drama', 'theme', 'music', ',', 'when', 'truman', \"'\", 's', 'world', 'is', 'still', 'beautiful', 'and', 'perfect', '.', 'when', 'the', 'movie', 'ends', ',', 'the', 'score', 'sounds', 'more', 'like', 'a', 'frantic', ',', 'driven', ',', 'tangerine', 'dream', 'opus', ',', 'while', 'still', 'keeping', 'the', 'same', 'timbre', '.', 'philip', 'glass', \"'\", 'epic', 'music', '(', 'from', 'powaqqatsi', ')', 'permeates', 'truman', \"'\", 's', 'scenes', 'of', 'suspicion', 'and', 'awakening', '.', '(', 'glass', 'has', 'a', 'small', 'cameo', 'as', 'a', 'keyboardist', 'for', 'the', 'show', '.', ')', 'and', 'the', 'pacing', 'of', 'the', 'story', 'was', 'brisk', '.', 'there', 'was', 'no', 'unnecessarily', 'long', 'setup', 'explaining', 'the', 'concept', 'behind', 'the', 'truman', 'show', ',', 'just', 'a', 'few', 'quick', 'title', 'cards', ',', 'a', 'few', 'interviews', ',', 'and', 'then', 'right', 'into', 'the', 'show', ',', 'and', 'the', 'movie', '.', 'one', 'of', 'the', 'first', 'scenes', 'is', 'of', 'the', 'studio', 'light', 'falling', ';', 'there', 'was', 'no', 'token', 'scene', 'of', 'truman', \"'\", 's', 'idyllic', 'life', 'before', 'it', 'falls', 'apart', ',', 'because', 'it', 'wasn', \"'\", 't', 'necessary', ',', 'we', 'pick', 'up', 'the', 'story', 'at', 'the', 'first', 'sign', 'of', 'trouble', ',', 'and', 'no', 'sooner', '.', 'there', \"'\", 's', 'also', 'no', 'point', 'in', 'the', 'movie', 'where', 'the', 'plot', 'slows', 'down', '.', 'it', \"'\", 's', 'a', 'quick', ',', 'straight', 'shot', 'to', 'the', 'movie', \"'\", 's', 'end', '.', 'in', 'terms', 'of', 'overall', 'quality', ',', 'i', 'would', 'compare', 'the', 'truman', 'show', 'to', 'niccol', \"'\", 's', 'gattaca', '.', 'both', 'films', 'are', 'well', 'made', 'with', 'interesting', 'stories', 'set', 'in', 'interesting', 'worlds', '.', 'but', 'neither', 'film', 'really', 'felt', 'like', 'it', 'capitalized', 'on', 'all', 'the', 'great', 'ideas', ';', 'neither', 'film', '\"', 'clicked', '\"', 'and', 'became', 'an', 'instant', 'classic', '.', 'nevertheless', ',', 'i', 'look', 'forward', 'to', 'niccol', \"'\", 's', 'next', 'film', ',', 'whatever', 'it', 'may', 'be', '.'], 'pos')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN5UsvzO04Z8"
      },
      "source": [
        "#Shuffling reviews so that classifier doesn't classify based on order\n",
        "random.shuffle(reviews)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu9gGo6o04aB"
      },
      "source": [
        "#Extracting all words from all the reviews, removing stop words and punctuations\n",
        "all_words = []\n",
        "for w in movie_reviews.words():\n",
        "    all_words.append(w.lower())\n",
        "\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "punct = set(['.','!','(',')','[',']','{','}','<','>',':',';', '-', ',','\\'','\"'\n",
        "             , '?'])\n",
        "\n",
        "stop_words = stop_words.union(punct)\n",
        "stop_words = list(stop_words)\n",
        "all_words = [w for w in all_words if not w in stop_words]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkF-xDqt04aH",
        "outputId": "cd575c29-2e39-4faa-8609-cb314a395749"
      },
      "source": [
        "#Creating frequency distribution of all_words\n",
        "all_words1 = nltk.FreqDist(all_words)\n",
        "all_words1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'plot': 1513,\n",
              "          'two': 1911,\n",
              "          'teen': 151,\n",
              "          'couples': 27,\n",
              "          'go': 1113,\n",
              "          'church': 69,\n",
              "          'party': 183,\n",
              "          'drink': 32,\n",
              "          'drive': 105,\n",
              "          'get': 1949,\n",
              "          'accident': 104,\n",
              "          'one': 5852,\n",
              "          'guys': 268,\n",
              "          'dies': 104,\n",
              "          'girlfriend': 218,\n",
              "          'continues': 88,\n",
              "          'see': 1749,\n",
              "          'life': 1586,\n",
              "          'nightmares': 26,\n",
              "          'deal': 219,\n",
              "          'watch': 603,\n",
              "          'movie': 5771,\n",
              "          'sorta': 10,\n",
              "          'find': 782,\n",
              "          'critique': 61,\n",
              "          'mind': 451,\n",
              "          'fuck': 17,\n",
              "          'generation': 96,\n",
              "          'touches': 55,\n",
              "          'cool': 208,\n",
              "          'idea': 386,\n",
              "          'presents': 78,\n",
              "          'bad': 1395,\n",
              "          'package': 30,\n",
              "          'makes': 992,\n",
              "          'review': 295,\n",
              "          'even': 2565,\n",
              "          'harder': 33,\n",
              "          'write': 119,\n",
              "          'since': 768,\n",
              "          'generally': 103,\n",
              "          'applaud': 10,\n",
              "          'films': 1536,\n",
              "          'attempt': 263,\n",
              "          'break': 175,\n",
              "          'mold': 14,\n",
              "          'mess': 159,\n",
              "          'head': 387,\n",
              "          'lost': 409,\n",
              "          'highway': 28,\n",
              "          '&': 293,\n",
              "          'memento': 10,\n",
              "          'good': 2411,\n",
              "          'ways': 189,\n",
              "          'making': 602,\n",
              "          'types': 48,\n",
              "          'folks': 74,\n",
              "          'snag': 2,\n",
              "          'correctly': 17,\n",
              "          'seem': 574,\n",
              "          'taken': 225,\n",
              "          'pretty': 528,\n",
              "          'neat': 32,\n",
              "          'concept': 114,\n",
              "          'executed': 46,\n",
              "          'terribly': 58,\n",
              "          'problems': 293,\n",
              "          'well': 1906,\n",
              "          'main': 399,\n",
              "          'problem': 396,\n",
              "          'simply': 428,\n",
              "          'jumbled': 12,\n",
              "          'starts': 316,\n",
              "          'normal': 111,\n",
              "          'downshifts': 2,\n",
              "          'fantasy': 97,\n",
              "          'world': 1037,\n",
              "          'audience': 914,\n",
              "          'member': 126,\n",
              "          'going': 888,\n",
              "          'dreams': 131,\n",
              "          'characters': 1859,\n",
              "          'coming': 275,\n",
              "          'back': 1060,\n",
              "          'dead': 418,\n",
              "          'others': 288,\n",
              "          'look': 835,\n",
              "          'like': 3690,\n",
              "          'strange': 185,\n",
              "          'apparitions': 5,\n",
              "          'disappearances': 3,\n",
              "          'looooot': 1,\n",
              "          'chase': 159,\n",
              "          'scenes': 1274,\n",
              "          'tons': 21,\n",
              "          'weird': 100,\n",
              "          'things': 852,\n",
              "          'happen': 220,\n",
              "          'explained': 70,\n",
              "          'personally': 44,\n",
              "          'trying': 566,\n",
              "          'unravel': 9,\n",
              "          'film': 9517,\n",
              "          'every': 947,\n",
              "          'give': 561,\n",
              "          'clue': 45,\n",
              "          'kind': 559,\n",
              "          'fed': 29,\n",
              "          'biggest': 149,\n",
              "          'obviously': 228,\n",
              "          'got': 470,\n",
              "          'big': 1064,\n",
              "          'secret': 184,\n",
              "          'hide': 40,\n",
              "          'seems': 1033,\n",
              "          'want': 560,\n",
              "          'completely': 440,\n",
              "          'final': 380,\n",
              "          'five': 284,\n",
              "          'minutes': 644,\n",
              "          'make': 1642,\n",
              "          'entertaining': 314,\n",
              "          'thrilling': 46,\n",
              "          'engaging': 79,\n",
              "          'meantime': 19,\n",
              "          'really': 1558,\n",
              "          'sad': 108,\n",
              "          'part': 714,\n",
              "          'arrow': 29,\n",
              "          'dig': 19,\n",
              "          'flicks': 81,\n",
              "          'actually': 837,\n",
              "          'figured': 29,\n",
              "          'half': 535,\n",
              "          'way': 1693,\n",
              "          'point': 685,\n",
              "          'strangeness': 6,\n",
              "          'start': 312,\n",
              "          'little': 1501,\n",
              "          'bit': 568,\n",
              "          'sense': 555,\n",
              "          'still': 1047,\n",
              "          'guess': 226,\n",
              "          'bottom': 93,\n",
              "          'line': 435,\n",
              "          'movies': 1206,\n",
              "          'always': 586,\n",
              "          'sure': 523,\n",
              "          'given': 502,\n",
              "          'password': 4,\n",
              "          'enter': 68,\n",
              "          'understanding': 57,\n",
              "          'mean': 242,\n",
              "          'showing': 147,\n",
              "          'melissa': 12,\n",
              "          'sagemiller': 8,\n",
              "          'running': 323,\n",
              "          'away': 655,\n",
              "          'visions': 31,\n",
              "          '20': 98,\n",
              "          'throughout': 302,\n",
              "          'plain': 82,\n",
              "          'lazy': 34,\n",
              "          'okay': 125,\n",
              "          'people': 1455,\n",
              "          'chasing': 43,\n",
              "          'know': 1217,\n",
              "          'need': 316,\n",
              "          'giving': 214,\n",
              "          'us': 1073,\n",
              "          'different': 430,\n",
              "          'offering': 38,\n",
              "          'insight': 54,\n",
              "          'apparently': 209,\n",
              "          'studio': 163,\n",
              "          'took': 164,\n",
              "          'director': 1237,\n",
              "          'chopped': 5,\n",
              "          'shows': 410,\n",
              "          'might': 635,\n",
              "          'decent': 164,\n",
              "          'somewhere': 127,\n",
              "          'suits': 45,\n",
              "          'decided': 104,\n",
              "          'turning': 80,\n",
              "          'music': 480,\n",
              "          'video': 322,\n",
              "          'edge': 104,\n",
              "          'would': 2109,\n",
              "          'actors': 706,\n",
              "          'although': 795,\n",
              "          'wes': 50,\n",
              "          'bentley': 9,\n",
              "          'seemed': 212,\n",
              "          'playing': 362,\n",
              "          'exact': 64,\n",
              "          'character': 2020,\n",
              "          'american': 559,\n",
              "          'beauty': 135,\n",
              "          'new': 1292,\n",
              "          'neighborhood': 21,\n",
              "          'kudos': 21,\n",
              "          'holds': 90,\n",
              "          'entire': 408,\n",
              "          'feeling': 225,\n",
              "          'unraveling': 2,\n",
              "          'overall': 160,\n",
              "          'stick': 69,\n",
              "          'entertain': 53,\n",
              "          'confusing': 94,\n",
              "          'rarely': 102,\n",
              "          'excites': 2,\n",
              "          'feels': 216,\n",
              "          'redundant': 14,\n",
              "          'runtime': 8,\n",
              "          'despite': 352,\n",
              "          'ending': 423,\n",
              "          'explanation': 69,\n",
              "          'craziness': 4,\n",
              "          'came': 185,\n",
              "          'oh': 216,\n",
              "          'horror': 473,\n",
              "          'slasher': 84,\n",
              "          'flick': 196,\n",
              "          'packaged': 3,\n",
              "          'someone': 401,\n",
              "          'assuming': 15,\n",
              "          'genre': 268,\n",
              "          'hot': 127,\n",
              "          'kids': 328,\n",
              "          'also': 1967,\n",
              "          'wrapped': 39,\n",
              "          'production': 300,\n",
              "          'years': 846,\n",
              "          'ago': 199,\n",
              "          'sitting': 93,\n",
              "          'shelves': 13,\n",
              "          'ever': 776,\n",
              "          'whatever': 136,\n",
              "          'skip': 45,\n",
              "          'joblo': 30,\n",
              "          'nightmare': 60,\n",
              "          'elm': 14,\n",
              "          'street': 140,\n",
              "          '3': 222,\n",
              "          '7': 115,\n",
              "          '/': 960,\n",
              "          '10': 449,\n",
              "          'blair': 98,\n",
              "          'witch': 108,\n",
              "          '2': 439,\n",
              "          'crow': 55,\n",
              "          '9': 75,\n",
              "          'salvation': 14,\n",
              "          '4': 190,\n",
              "          'stir': 27,\n",
              "          'echoes': 31,\n",
              "          '8': 140,\n",
              "          'happy': 215,\n",
              "          'bastard': 46,\n",
              "          'quick': 139,\n",
              "          'damn': 88,\n",
              "          'y2k': 4,\n",
              "          'bug': 81,\n",
              "          'starring': 184,\n",
              "          'jamie': 42,\n",
              "          'lee': 266,\n",
              "          'curtis': 37,\n",
              "          'another': 1121,\n",
              "          'baldwin': 89,\n",
              "          'brother': 268,\n",
              "          'william': 206,\n",
              "          'time': 2411,\n",
              "          'story': 2169,\n",
              "          'regarding': 31,\n",
              "          'crew': 214,\n",
              "          'tugboat': 2,\n",
              "          'comes': 733,\n",
              "          'across': 221,\n",
              "          'deserted': 21,\n",
              "          'russian': 68,\n",
              "          'tech': 29,\n",
              "          'ship': 264,\n",
              "          'kick': 52,\n",
              "          'power': 238,\n",
              "          'within': 227,\n",
              "          'gore': 110,\n",
              "          'bringing': 81,\n",
              "          'action': 1172,\n",
              "          'sequences': 293,\n",
              "          'virus': 77,\n",
              "          'empty': 67,\n",
              "          'flash': 62,\n",
              "          'substance': 73,\n",
              "          'middle': 222,\n",
              "          'nowhere': 98,\n",
              "          'origin': 8,\n",
              "          'pink': 24,\n",
              "          'flashy': 41,\n",
              "          'thing': 809,\n",
              "          'hit': 285,\n",
              "          'mir': 7,\n",
              "          'course': 648,\n",
              "          'donald': 38,\n",
              "          'sutherland': 39,\n",
              "          'stumbling': 15,\n",
              "          'around': 903,\n",
              "          'drunkenly': 2,\n",
              "          'hey': 70,\n",
              "          'let': 425,\n",
              "          'robots': 27,\n",
              "          'acting': 695,\n",
              "          'average': 119,\n",
              "          'likes': 99,\n",
              "          'likely': 164,\n",
              "          'work': 1020,\n",
              "          'halloween': 60,\n",
              "          'h20': 7,\n",
              "          'wasted': 118,\n",
              "          'real': 915,\n",
              "          'star': 761,\n",
              "          'stan': 12,\n",
              "          'winston': 4,\n",
              "          'robot': 45,\n",
              "          'design': 87,\n",
              "          'schnazzy': 1,\n",
              "          'cgi': 50,\n",
              "          'occasional': 62,\n",
              "          'shot': 348,\n",
              "          'picking': 28,\n",
              "          'brain': 93,\n",
              "          'body': 269,\n",
              "          'parts': 207,\n",
              "          'turn': 363,\n",
              "          'otherwise': 156,\n",
              "          'much': 2049,\n",
              "          'sunken': 4,\n",
              "          'jaded': 12,\n",
              "          'viewer': 218,\n",
              "          'thankful': 7,\n",
              "          'invention': 11,\n",
              "          'timex': 1,\n",
              "          'indiglo': 1,\n",
              "          'based': 389,\n",
              "          'late': 238,\n",
              "          '1960': 22,\n",
              "          'television': 220,\n",
              "          'show': 741,\n",
              "          'name': 392,\n",
              "          'mod': 17,\n",
              "          'squad': 40,\n",
              "          'tells': 255,\n",
              "          'tale': 216,\n",
              "          'three': 695,\n",
              "          'reformed': 7,\n",
              "          'criminals': 35,\n",
              "          'employ': 16,\n",
              "          'police': 241,\n",
              "          'undercover': 28,\n",
              "          'however': 989,\n",
              "          'wrong': 385,\n",
              "          'evidence': 66,\n",
              "          'gets': 865,\n",
              "          'stolen': 58,\n",
              "          'immediately': 163,\n",
              "          'suspicion': 19,\n",
              "          'ads': 33,\n",
              "          'cuts': 60,\n",
              "          'claire': 70,\n",
              "          'dane': 5,\n",
              "          'nice': 344,\n",
              "          'hair': 109,\n",
              "          'cute': 134,\n",
              "          'outfits': 21,\n",
              "          'car': 321,\n",
              "          'chases': 50,\n",
              "          'stuff': 208,\n",
              "          'blowing': 26,\n",
              "          'sounds': 133,\n",
              "          'first': 1836,\n",
              "          'fifteen': 64,\n",
              "          'quickly': 255,\n",
              "          'becomes': 526,\n",
              "          'apparent': 100,\n",
              "          'certainly': 361,\n",
              "          'slick': 39,\n",
              "          'looking': 501,\n",
              "          'complete': 197,\n",
              "          'costumes': 71,\n",
              "          'enough': 910,\n",
              "          'best': 1333,\n",
              "          'described': 57,\n",
              "          'cross': 111,\n",
              "          'hour': 355,\n",
              "          'long': 836,\n",
              "          'cop': 208,\n",
              "          'stretched': 19,\n",
              "          'span': 19,\n",
              "          'single': 239,\n",
              "          'clich': 72,\n",
              "          'matter': 321,\n",
              "          'elements': 236,\n",
              "          'recycled': 24,\n",
              "          'everything': 530,\n",
              "          'already': 289,\n",
              "          'seen': 910,\n",
              "          'nothing': 804,\n",
              "          'spectacular': 83,\n",
              "          'sometimes': 277,\n",
              "          'bordering': 6,\n",
              "          'wooden': 48,\n",
              "          'danes': 26,\n",
              "          'omar': 12,\n",
              "          'epps': 16,\n",
              "          'deliver': 92,\n",
              "          'lines': 320,\n",
              "          'bored': 83,\n",
              "          'transfers': 3,\n",
              "          'onto': 119,\n",
              "          'escape': 158,\n",
              "          'relatively': 66,\n",
              "          'unscathed': 8,\n",
              "          'giovanni': 14,\n",
              "          'ribisi': 24,\n",
              "          'plays': 752,\n",
              "          'resident': 8,\n",
              "          'crazy': 99,\n",
              "          'man': 1396,\n",
              "          'ultimately': 158,\n",
              "          'worth': 319,\n",
              "          'watching': 493,\n",
              "          'unfortunately': 382,\n",
              "          'save': 273,\n",
              "          'convoluted': 31,\n",
              "          'apart': 118,\n",
              "          'occupying': 5,\n",
              "          'screen': 705,\n",
              "          'young': 743,\n",
              "          'cast': 769,\n",
              "          'clothes': 51,\n",
              "          'hip': 69,\n",
              "          'soundtrack': 148,\n",
              "          'appears': 243,\n",
              "          'geared': 14,\n",
              "          'towards': 182,\n",
              "          'teenage': 103,\n",
              "          'mindset': 10,\n",
              "          'r': 180,\n",
              "          'rating': 151,\n",
              "          'content': 77,\n",
              "          'justify': 23,\n",
              "          'juvenile': 22,\n",
              "          'older': 103,\n",
              "          'information': 100,\n",
              "          'literally': 106,\n",
              "          'spoon': 22,\n",
              "          'hard': 587,\n",
              "          'instead': 565,\n",
              "          'telling': 133,\n",
              "          'dialogue': 519,\n",
              "          'poorly': 94,\n",
              "          'written': 409,\n",
              "          'extremely': 248,\n",
              "          'predictable': 182,\n",
              "          'progresses': 47,\n",
              "          'care': 304,\n",
              "          'heroes': 101,\n",
              "          'jeopardy': 28,\n",
              "          'basing': 4,\n",
              "          'nobody': 88,\n",
              "          'remembers': 9,\n",
              "          'questionable': 20,\n",
              "          'wisdom': 35,\n",
              "          'especially': 456,\n",
              "          'considers': 19,\n",
              "          'target': 94,\n",
              "          'fact': 805,\n",
              "          'number': 222,\n",
              "          'memorable': 147,\n",
              "          'counted': 13,\n",
              "          'hand': 378,\n",
              "          'missing': 116,\n",
              "          'finger': 25,\n",
              "          'times': 568,\n",
              "          'checked': 7,\n",
              "          'six': 147,\n",
              "          'clear': 184,\n",
              "          'indication': 11,\n",
              "          'cash': 92,\n",
              "          'spending': 46,\n",
              "          'dollar': 55,\n",
              "          'judging': 34,\n",
              "          'rash': 7,\n",
              "          'awful': 132,\n",
              "          'seeing': 339,\n",
              "          'avoid': 91,\n",
              "          'costs': 25,\n",
              "          'quest': 69,\n",
              "          'camelot': 11,\n",
              "          'warner': 48,\n",
              "          'bros': 24,\n",
              "          'feature': 230,\n",
              "          'length': 98,\n",
              "          'fully': 102,\n",
              "          'animated': 179,\n",
              "          'steal': 70,\n",
              "          'clout': 9,\n",
              "          'disney': 290,\n",
              "          'cartoon': 88,\n",
              "          'empire': 41,\n",
              "          'mouse': 51,\n",
              "          'reason': 437,\n",
              "          'worried': 29,\n",
              "          'recent': 211,\n",
              "          'challenger': 2,\n",
              "          'throne': 18,\n",
              "          'last': 843,\n",
              "          'fall': 239,\n",
              "          'promising': 54,\n",
              "          'flawed': 49,\n",
              "          '20th': 28,\n",
              "          'century': 121,\n",
              "          'fox': 111,\n",
              "          'anastasia': 22,\n",
              "          'hercules': 16,\n",
              "          'lively': 32,\n",
              "          'colorful': 51,\n",
              "          'palate': 4,\n",
              "          'beat': 71,\n",
              "          'hands': 148,\n",
              "          'crown': 15,\n",
              "          '1997': 112,\n",
              "          'piece': 244,\n",
              "          'animation': 142,\n",
              "          'year': 886,\n",
              "          'contest': 24,\n",
              "          'arrival': 37,\n",
              "          'magic': 92,\n",
              "          'kingdom': 19,\n",
              "          'mediocre': 74,\n",
              "          '--': 1815,\n",
              "          'pocahontas': 11,\n",
              "          'keeping': 88,\n",
              "          'score': 212,\n",
              "          'nearly': 307,\n",
              "          'dull': 134,\n",
              "          'revolves': 52,\n",
              "          'adventures': 53,\n",
              "          'free': 159,\n",
              "          'spirited': 43,\n",
              "          'kayley': 4,\n",
              "          'voiced': 57,\n",
              "          'jessalyn': 1,\n",
              "          'gilsig': 1,\n",
              "          'early': 303,\n",
              "          'daughter': 317,\n",
              "          'belated': 2,\n",
              "          'knight': 37,\n",
              "          'king': 256,\n",
              "          'arthur': 45,\n",
              "          'round': 49,\n",
              "          'table': 53,\n",
              "          'dream': 164,\n",
              "          'follow': 185,\n",
              "          'father': 492,\n",
              "          'footsteps': 17,\n",
              "          'chance': 223,\n",
              "          'evil': 429,\n",
              "          'warlord': 3,\n",
              "          'ruber': 1,\n",
              "          'gary': 77,\n",
              "          'oldman': 33,\n",
              "          'ex': 165,\n",
              "          'gone': 195,\n",
              "          'steals': 59,\n",
              "          'magical': 51,\n",
              "          'sword': 44,\n",
              "          'excalibur': 3,\n",
              "          'accidentally': 57,\n",
              "          'loses': 85,\n",
              "          'dangerous': 81,\n",
              "          'booby': 4,\n",
              "          'trapped': 52,\n",
              "          'forest': 45,\n",
              "          'help': 537,\n",
              "          'hunky': 12,\n",
              "          'blind': 44,\n",
              "          'timberland': 2,\n",
              "          'dweller': 2,\n",
              "          'garrett': 9,\n",
              "          'carey': 13,\n",
              "          'elwes': 6,\n",
              "          'headed': 75,\n",
              "          'dragon': 56,\n",
              "          'eric': 64,\n",
              "          'idle': 23,\n",
              "          'rickles': 4,\n",
              "          'arguing': 17,\n",
              "          'able': 339,\n",
              "          'medieval': 17,\n",
              "          'sexist': 14,\n",
              "          'prove': 102,\n",
              "          'fighter': 32,\n",
              "          'side': 341,\n",
              "          'pure': 90,\n",
              "          'showmanship': 4,\n",
              "          'essential': 34,\n",
              "          'element': 150,\n",
              "          'expected': 138,\n",
              "          'climb': 16,\n",
              "          'high': 624,\n",
              "          'ranks': 24,\n",
              "          'differentiates': 2,\n",
              "          'something': 1061,\n",
              "          'saturday': 53,\n",
              "          'morning': 66,\n",
              "          'subpar': 3,\n",
              "          'instantly': 41,\n",
              "          'forgettable': 30,\n",
              "          'songs': 119,\n",
              "          'integrated': 7,\n",
              "          'computerized': 4,\n",
              "          'footage': 104,\n",
              "          'compare': 41,\n",
              "          'run': 354,\n",
              "          'angry': 89,\n",
              "          'ogre': 20,\n",
              "          'herc': 2,\n",
              "          'battle': 230,\n",
              "          'hydra': 2,\n",
              "          'rest': 431,\n",
              "          'case': 420,\n",
              "          'stink': 5,\n",
              "          'none': 242,\n",
              "          'remotely': 50,\n",
              "          'interesting': 638,\n",
              "          'race': 127,\n",
              "          'bland': 84,\n",
              "          'end': 1062,\n",
              "          'tie': 34,\n",
              "          'win': 112,\n",
              "          'comedy': 840,\n",
              "          'shtick': 14,\n",
              "          'awfully': 27,\n",
              "          'cloying': 5,\n",
              "          'least': 676,\n",
              "          'signs': 53,\n",
              "          'pulse': 23,\n",
              "          'fans': 245,\n",
              "          \"-'\": 3,\n",
              "          '90s': 41,\n",
              "          'tgif': 2,\n",
              "          'thrilled': 15,\n",
              "          'jaleel': 1,\n",
              "          'urkel': 2,\n",
              "          'white': 314,\n",
              "          'bronson': 20,\n",
              "          'balki': 1,\n",
              "          'pinchot': 2,\n",
              "          'sharing': 14,\n",
              "          'nicely': 98,\n",
              "          'realized': 88,\n",
              "          'though': 940,\n",
              "          'loss': 54,\n",
              "          'recall': 52,\n",
              "          'specific': 36,\n",
              "          'providing': 46,\n",
              "          'voice': 275,\n",
              "          'talent': 223,\n",
              "          'enthusiastic': 18,\n",
              "          'paired': 9,\n",
              "          'singers': 10,\n",
              "          'sound': 245,\n",
              "          'musical': 154,\n",
              "          'moments': 447,\n",
              "          'jane': 83,\n",
              "          'seymour': 8,\n",
              "          'celine': 10,\n",
              "          'dion': 2,\n",
              "          'must': 618,\n",
              "          'strain': 14,\n",
              "          'aside': 118,\n",
              "          'children': 336,\n",
              "          'probably': 539,\n",
              "          'adults': 85,\n",
              "          'grievous': 3,\n",
              "          'error': 15,\n",
              "          'lack': 237,\n",
              "          'personality': 116,\n",
              "          'learn': 172,\n",
              "          'goes': 646,\n",
              "          'synopsis': 67,\n",
              "          'mentally': 37,\n",
              "          'unstable': 15,\n",
              "          'undergoing': 3,\n",
              "          'psychotherapy': 2,\n",
              "          'saves': 43,\n",
              "          'boy': 362,\n",
              "          'potentially': 39,\n",
              "          'fatal': 39,\n",
              "          'falls': 239,\n",
              "          'love': 1119,\n",
              "          'mother': 437,\n",
              "          'fledgling': 7,\n",
              "          'restauranteur': 2,\n",
              "          'unsuccessfully': 9,\n",
              "          'attempting': 55,\n",
              "          'gain': 42,\n",
              "          'woman': 554,\n",
              "          'favor': 47,\n",
              "          'takes': 674,\n",
              "          'pictures': 117,\n",
              "          'kills': 78,\n",
              "          'comments': 53,\n",
              "          'stalked': 23,\n",
              "          'yet': 608,\n",
              "          'seemingly': 124,\n",
              "          'endless': 57,\n",
              "          'string': 39,\n",
              "          'spurned': 4,\n",
              "          'psychos': 4,\n",
              "          'getting': 406,\n",
              "          'revenge': 100,\n",
              "          'type': 214,\n",
              "          'stable': 15,\n",
              "          'category': 40,\n",
              "          '1990s': 23,\n",
              "          'industry': 87,\n",
              "          'theatrical': 61,\n",
              "          'direct': 77,\n",
              "          'proliferation': 3,\n",
              "          'may': 857,\n",
              "          'due': 196,\n",
              "          'typically': 28,\n",
              "          'inexpensive': 3,\n",
              "          'produce': 44,\n",
              "          'special': 574,\n",
              "          'effects': 649,\n",
              "          'stars': 399,\n",
              "          'serve': 79,\n",
              "          'vehicles': 25,\n",
              "          'nudity': 73,\n",
              "          'allowing': 42,\n",
              "          'frequent': 35,\n",
              "          'night': 435,\n",
              "          'cable': 49,\n",
              "          'wavers': 1,\n",
              "          'slightly': 151,\n",
              "          'norm': 26,\n",
              "          'respect': 92,\n",
              "          'psycho': 61,\n",
              "          'never': 1374,\n",
              "          'affair': 96,\n",
              "          'contrary': 27,\n",
              "          'rejected': 19,\n",
              "          'rather': 621,\n",
              "          'lover': 94,\n",
              "          'wife': 588,\n",
              "          'husband': 260,\n",
              "          'entry': 45,\n",
              "          'doomed': 29,\n",
              "          'collect': 19,\n",
              "          'dust': 21,\n",
              "          'viewed': 45,\n",
              "          'midnight': 50,\n",
              "          'provide': 126,\n",
              "          'suspense': 202,\n",
              "          'sets': 241,\n",
              "          'interspersed': 5,\n",
              "          'opening': 306,\n",
              "          'credits': 203,\n",
              "          'instance': 75,\n",
              "          'serious': 216,\n",
              "          'sounding': 34,\n",
              "          'narrator': 37,\n",
              "          'spouts': 4,\n",
              "          'statistics': 1,\n",
              "          'stalkers': 2,\n",
              "          'ponders': 7,\n",
              "          'cause': 98,\n",
              "          'stalk': 4,\n",
              "          'implicitly': 3,\n",
              "          'implied': 9,\n",
              "          'men': 532,\n",
              "          'shown': 131,\n",
              "          'snapshot': 1,\n",
              "          'actor': 546,\n",
              "          'jay': 100,\n",
              "          'underwood': 11,\n",
              "          'states': 110,\n",
              "          'daryl': 24,\n",
              "          'gleason': 2,\n",
              "          'stalker': 10,\n",
              "          'brooke': 13,\n",
              "          'daniels': 27,\n",
              "          'meant': 91,\n",
              "          'called': 391,\n",
              "          'guesswork': 1,\n",
              "          'required': 53,\n",
              "          'proceeds': 29,\n",
              "          'begins': 392,\n",
              "          'obvious': 292,\n",
              "          'sequence': 366,\n",
              "          'contrived': 77,\n",
              "          'quite': 660,\n",
              "          'brings': 202,\n",
              "          'victim': 113,\n",
              "          'together': 522,\n",
              "          'obsesses': 4,\n",
              "          'follows': 170,\n",
              "          'tries': 370,\n",
              "          'woo': 94,\n",
              "          'plans': 90,\n",
              "          'become': 511,\n",
              "          'desperate': 101,\n",
              "          'elaborate': 63,\n",
              "          'include': 110,\n",
              "          'cliche': 65,\n",
              "          'murdered': 55,\n",
              "          'pet': 40,\n",
              "          'require': 36,\n",
              "          'found': 398,\n",
              "          'exception': 102,\n",
              "          'cat': 59,\n",
              "          'shower': 31,\n",
              "          'events': 201,\n",
              "          'lead': 251,\n",
              "          'inevitable': 70,\n",
              "          'showdown': 37,\n",
              "          'survives': 20,\n",
              "          'invariably': 6,\n",
              "          'conclusion': 122,\n",
              "          'turkey': 40,\n",
              "          'uniformly': 15,\n",
              "          'adequate': 38,\n",
              "          'anything': 618,\n",
              "          'home': 550,\n",
              "          'either': 386,\n",
              "          'turns': 403,\n",
              "          'toward': 100,\n",
              "          'melodrama': 36,\n",
              "          'overdoes': 4,\n",
              "          'words': 215,\n",
              "          'manages': 248,\n",
              "          'creepy': 93,\n",
              "          'pass': 98,\n",
              "          'demands': 44,\n",
              "          'maryam': 1,\n",
              "          'abo': 3,\n",
              "          'close': 289,\n",
              "          'played': 791,\n",
              "          'bond': 155,\n",
              "          'chick': 33,\n",
              "          'living': 234,\n",
              "          'daylights': 1,\n",
              "          'equally': 110,\n",
              "          'title': 297,\n",
              "          'ditzy': 14,\n",
              "          'strong': 268,\n",
              "          'independent': 45,\n",
              "          'business': 193,\n",
              "          'owner': 99,\n",
              "          'needs': 221,\n",
              "          'proceed': 26,\n",
              "          'example': 300,\n",
              "          'suspicions': 5,\n",
              "          'ensure': 15,\n",
              "          'use': 398,\n",
              "          'excuse': 75,\n",
              "          'decides': 189,\n",
              "          'return': 195,\n",
              "          'toolbox': 2,\n",
              "          'left': 413,\n",
              "          'place': 615,\n",
              "          'house': 377,\n",
              "          'leave': 215,\n",
              "          'door': 112,\n",
              "          'answers': 58,\n",
              "          'opens': 175,\n",
              "          'wanders': 30,\n",
              "          'returns': 111,\n",
              "          'enters': 34,\n",
              "          'heroine': 56,\n",
              "          'danger': 62,\n",
              "          'somehow': 207,\n",
              "          'parked': 4,\n",
              "          'front': 135,\n",
              "          'right': 798,\n",
              "          'oblivious': 17,\n",
              "          'presence': 195,\n",
              "          'inside': 157,\n",
              "          'whole': 495,\n",
              "          'episode': 98,\n",
              "          'places': 99,\n",
              "          'incredible': 95,\n",
              "          'suspension': 19,\n",
              "          'disbelief': 48,\n",
              "          'questions': 178,\n",
              "          'validity': 2,\n",
              "          'intelligence': 125,\n",
              "          'receives': 32,\n",
              "          'highly': 136,\n",
              "          'derivative': 22,\n",
              "          'somewhat': 188,\n",
              "          'boring': 270,\n",
              "          'cannot': 147,\n",
              "          'watched': 81,\n",
              "          'rated': 146,\n",
              "          'mostly': 247,\n",
              "          'several': 419,\n",
              "          'murder': 250,\n",
              "          'brief': 140,\n",
              "          'strip': 48,\n",
              "          'bar': 74,\n",
              "          'offensive': 75,\n",
              "          'many': 1268,\n",
              "          'thrillers': 62,\n",
              "          'mood': 97,\n",
              "          'stake': 14,\n",
              "          'else': 387,\n",
              "          'capsule': 49,\n",
              "          '2176': 4,\n",
              "          'planet': 243,\n",
              "          'mars': 146,\n",
              "          'taking': 242,\n",
              "          'custody': 19,\n",
              "          'accused': 44,\n",
              "          'murderer': 42,\n",
              "          'face': 357,\n",
              "          'menace': 107,\n",
              "          'lot': 677,\n",
              "          'fighting': 101,\n",
              "          'john': 798,\n",
              "          'carpenter': 77,\n",
              "          'reprises': 12,\n",
              "          'ideas': 144,\n",
              "          'previous': 186,\n",
              "          'assault': 31,\n",
              "          'precinct': 8,\n",
              "          '13': 93,\n",
              "          'homage': 50,\n",
              "          '0': 55,\n",
              "          '+': 158,\n",
              "          'believes': 80,\n",
              "          'fight': 323,\n",
              "          'horrible': 103,\n",
              "          'writer': 312,\n",
              "          'supposedly': 78,\n",
              "          'expert': 45,\n",
              "          'mistake': 69,\n",
              "          'ghosts': 45,\n",
              "          'drawn': 89,\n",
              "          'humans': 135,\n",
              "          'surprisingly': 191,\n",
              "          'low': 179,\n",
              "          'powered': 13,\n",
              "          'alien': 378,\n",
              "          'addition': 103,\n",
              "          'anybody': 44,\n",
              "          'made': 1084,\n",
              "          'grounds': 12,\n",
              "          'sue': 22,\n",
              "          'chock': 11,\n",
              "          'full': 375,\n",
              "          'pieces': 96,\n",
              "          'prince': 64,\n",
              "          'darkness': 51,\n",
              "          'surprising': 100,\n",
              "          'managed': 85,\n",
              "          'fit': 76,\n",
              "          'admittedly': 39,\n",
              "          'novel': 257,\n",
              "          'science': 235,\n",
              "          'fiction': 258,\n",
              "          'experience': 235,\n",
              "          'terraformed': 1,\n",
              "          'walk': 106,\n",
              "          'surface': 74,\n",
              "          'without': 697,\n",
              "          'breathing': 24,\n",
              "          'gear': 14,\n",
              "          'budget': 183,\n",
              "          'mentioned': 94,\n",
              "          'gravity': 20,\n",
              "          'increased': 7,\n",
              "          'earth': 317,\n",
              "          'easier': 39,\n",
              "          'society': 155,\n",
              "          'changed': 80,\n",
              "          'advanced': 26,\n",
              "          'culture': 104,\n",
              "          'women': 275,\n",
              "          'positions': 8,\n",
              "          'control': 145,\n",
              "          'view': 164,\n",
              "          'stagnated': 1,\n",
              "          'female': 143,\n",
              "          'beyond': 181,\n",
              "          'minor': 134,\n",
              "          'technological': 11,\n",
              "          ...})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtMc6guN04aN"
      },
      "source": [
        "#Taking first 3000 words from all_words1 for training classifier\n",
        "word_features = list(all_words1.keys())[:3000]\n",
        "\n",
        "#Function to create features that indicate whether particular word is present in review or not\n",
        "def find_features(review):\n",
        "    words = set(review)\n",
        "    features = {}\n",
        "    for w in word_features:\n",
        "        features[w] = (w in words)\n",
        "    return features\n",
        "\n",
        "# Creating feturesets using above function\n",
        "featuresets = [(find_features(rev), category) for (rev, category) in reviews]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDI7PnqM04aR"
      },
      "source": [
        "#Splitting data\n",
        "training = featuresets[:1800]\n",
        "testing = featuresets[1800:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljN-vnmV04aW",
        "outputId": "aa5a8cff-77ae-4544-e7f2-881cd4d1c89c"
      },
      "source": [
        "#Naive Bayes Classifier\n",
        "\n",
        "nbclassifier = nltk.NaiveBayesClassifier.train(training)\n",
        "print(\"Naive Bayes Classifier Accuracy: \", nltk.classify.accuracy(nbclassifier, testing))\n",
        "nbclassifier.show_most_informative_features(10)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naive Bayes Classifier Accuracy:  0.82\n",
            "Most Informative Features\n",
            "                  alicia = True              neg : pos    =     11.1 : 1.0\n",
            "                  regard = True              pos : neg    =     10.3 : 1.0\n",
            "                   sucks = True              neg : pos    =      9.9 : 1.0\n",
            "                  annual = True              pos : neg    =      8.9 : 1.0\n",
            "                bothered = True              neg : pos    =      8.4 : 1.0\n",
            "           unimaginative = True              neg : pos    =      7.7 : 1.0\n",
            "                   groan = True              neg : pos    =      7.7 : 1.0\n",
            "                  shoddy = True              neg : pos    =      7.0 : 1.0\n",
            "                  crappy = True              neg : pos    =      7.0 : 1.0\n",
            "                  turkey = True              neg : pos    =      7.0 : 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36QqUsCX04ab",
        "outputId": "ba197ecf-92f6-4f8f-91d5-5d504c7df066"
      },
      "source": [
        "#Logistic Regression Classifier\n",
        "LR_classifier = SklearnClassifier(LogisticRegression())\n",
        "LR_classifier.train(training)\n",
        "print(\"LR_classifier accuracy:\", nltk.classify.accuracy(LR_classifier, testing))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LR_classifier accuracy: 0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBD5iOj804af",
        "outputId": "e105f30c-253b-4d6d-a347-42597b9acd24"
      },
      "source": [
        "#SVC Classifier\n",
        "SVC_classifier = SklearnClassifier(SVC())\n",
        "SVC_classifier.train(training)\n",
        "print(\"SVC_classifier accuracy: \", nltk.classify.accuracy(SVC_classifier, testing))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVC_classifier accuracy:  0.785\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf-rtChr04al",
        "outputId": "9fffb164-4748-4681-c89d-47006fa76d37"
      },
      "source": [
        "#Linear SVC Classifer\n",
        "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
        "LinearSVC_classifier.train(training)\n",
        "print(\"LinearSVC_classifier accuracy:\", nltk.classify.accuracy(LinearSVC_classifier, testing))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LinearSVC_classifier accuracy: 0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_MXdapV04ap",
        "outputId": "54dc05cf-4266-440a-a302-2b8593718d23"
      },
      "source": [
        "# Decision Tree Classifier\n",
        "DT_classifier = SklearnClassifier(DecisionTreeClassifier())\n",
        "DT_classifier.train(training)\n",
        "print(\"DT_classifier accuracy:\", nltk.classify.accuracy(DT_classifier, testing))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DT_classifier accuracy: 0.655\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stKkMwA-04at",
        "outputId": "ffa75c95-ea42-45c4-b39b-cecbbb079b6f"
      },
      "source": [
        "#Decision tree with maximum depth 3\n",
        "DT_classifier1 = SklearnClassifier(DecisionTreeClassifier(max_depth= 3))\n",
        "DT_classifier1.train(training)\n",
        "print(\"DT_classifier1 accuracy:\", nltk.classify.accuracy(DT_classifier1, testing))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DT_classifier1 accuracy: 0.655\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOAqxxEz04ay",
        "outputId": "1501ac47-c1f0-446e-a9b1-2b97144d1325"
      },
      "source": [
        "#Decision tree with maximum depth 5\n",
        "DT_classifier2 = SklearnClassifier(DecisionTreeClassifier(max_depth= 5))\n",
        "DT_classifier2.train(training)\n",
        "print(\"DT_classifier2 accuracy:\", nltk.classify.accuracy(DT_classifier2, testing))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DT_classifier2 accuracy: 0.69\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Je3rON_t04a2"
      },
      "source": [
        "# Creating a voted classifer which takes majority vote of the above classifiers to classify reviews\n",
        "\n",
        "#Function for voteclassifier\n",
        "class VoteClassifier(ClassifierI):\n",
        "    #Initializaton method\n",
        "    def __init__(self, *classifiers):\n",
        "        self._classifiers = classifiers\n",
        "    #Method to classify according to mode\n",
        "    def classify(self, features):\n",
        "        votes = []\n",
        "        for c in self._classifiers:\n",
        "            v = c.classify(features)\n",
        "            votes.append(v)\n",
        "        return mode(votes)\n",
        "    #Method to calculate confidence by ratio of majority votes to total votes\n",
        "    def confidence(self, features):\n",
        "        votes = []\n",
        "        for c in self._classifiers:\n",
        "            v = c.classify(features)\n",
        "            votes.append(v)\n",
        "\n",
        "        choice_votes = votes.count(mode(votes))\n",
        "        conf = choice_votes/len(votes)\n",
        "        return conf\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzG_FjLG04a6",
        "outputId": "5accc5e0-96cf-4e68-858b-bf3ca922fa05"
      },
      "source": [
        "#Voted classifier with all of the above classifiers\n",
        "voted_classifier = VoteClassifier(nbclassifier,\n",
        "                                  LR_classifier,\n",
        "                                  SVC_classifier,\n",
        "                                  LinearSVC_classifier,\n",
        "                                  DT_classifier2)\n",
        "\n",
        "print(\"voted_classifier accuracy percent:\", nltk.classify.accuracy(voted_classifier, testing))\n",
        "print(\"Prediction for first instance in testing\")\n",
        "print(\"Classification:\", voted_classifier.classify(testing[0][0]), \"Confidence:\",voted_classifier.confidence(testing[0][0]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "voted_classifier accuracy percent: 0.83\n",
            "Prediction for first instance in testing\n",
            "Classification: neg Confidence: 0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6C4vKIl04bB",
        "outputId": "f401c8f9-2dbb-4989-ea93-8b4bfb75f25f"
      },
      "source": [
        "#Voted classifier with some of the above classifiers\n",
        "voted_classifier = VoteClassifier(nbclassifier,\n",
        "                                  LR_classifier,\n",
        "                                  SVC_classifier)\n",
        "\n",
        "print(\"voted_classifier accuracy percent:\", nltk.classify.accuracy(voted_classifier, testing))\n",
        "print(\"Prediction for first instance in testing\")\n",
        "print(\"Classification:\", voted_classifier.classify(testing[0][0]), \"Confidence:\",voted_classifier.confidence(testing[0][0]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "voted_classifier accuracy percent: 0.83\n",
            "Prediction for first instance in testing\n",
            "Classification: neg Confidence: 0.6666666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAfYCqjF04bF"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fM6cz3fc04bJ"
      },
      "source": [
        "accuracy_table = {'Datasets' : 'movie_reviews',\n",
        "                'Naive Bayes': nltk.classify.accuracy(nbclassifier, testing),\n",
        "                'SVM': nltk.classify.accuracy(LinearSVC_classifier, testing),\n",
        "                'Decision Tree': nltk.classify.accuracy(DT_classifier2, testing),\n",
        "                'Logistic Regression': nltk.classify.accuracy(LR_classifier, testing)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxFe9eUL04bN"
      },
      "source": [
        "accuracy_table = pd.DataFrame([accuracy_table], columns=accuracy_table.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PkQ59GC04bR",
        "outputId": "28328f48-24e2-4ed8-b7b4-9acb582403dc"
      },
      "source": [
        "accuracy_table"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style>\n",
              "    .dataframe thead tr:only-child th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Datasets</th>\n",
              "      <th>Naive Bayes</th>\n",
              "      <th>SVM</th>\n",
              "      <th>Decision Tree</th>\n",
              "      <th>Logistic Regression</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>movie_reviews</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Datasets  Naive Bayes  SVM  Decision Tree  Logistic Regression\n",
              "0  movie_reviews         0.82  0.8           0.69                  0.8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auGJlPLc04bU"
      },
      "source": [
        "###### Trying to increase accuracy by taking most common 3000 words as features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzZ9hnsf04bV"
      },
      "source": [
        "#Creating features with 3000 most common words\n",
        "word_features = list(all_words1.most_common(3000))\n",
        "word_features = [word_features[i][0] for i in range(len(word_features))]\n",
        "\n",
        "#Function to create features that indicate whether particular word is present in review or not\n",
        "def find_features(review):\n",
        "    words = set(review)\n",
        "    features = {}\n",
        "    for w in word_features:\n",
        "        features[w] = (w in words)\n",
        "    return features\n",
        "\n",
        "# Creating feturesets using above function\n",
        "featuresets = [(find_features(rev), category) for (rev, category) in reviews]\n",
        "\n",
        "#Splitting data\n",
        "training = featuresets[:1800]\n",
        "testing = featuresets[1800:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a80pN0m04bZ",
        "outputId": "303c85f1-00c5-4295-f755-7b76756e40f8"
      },
      "source": [
        "#Naive Bayes Classifier\n",
        "\n",
        "nbclassifier = nltk.NaiveBayesClassifier.train(training)\n",
        "print(\"Naive Bayes Classifier Accuracy: \", nltk.classify.accuracy(nbclassifier, testing))\n",
        "nbclassifier.show_most_informative_features(30)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naive Bayes Classifier Accuracy:  0.79\n",
            "Most Informative Features\n",
            "                  seagal = True              neg : pos    =     13.1 : 1.0\n",
            "                  alicia = True              neg : pos    =     11.1 : 1.0\n",
            "             outstanding = True              pos : neg    =     10.0 : 1.0\n",
            "                  finest = True              pos : neg    =      9.8 : 1.0\n",
            "                   mulan = True              pos : neg    =      7.6 : 1.0\n",
            "             beautifully = True              pos : neg    =      7.6 : 1.0\n",
            "            breathtaking = True              pos : neg    =      7.6 : 1.0\n",
            "                  tucker = True              pos : neg    =      7.4 : 1.0\n",
            "                  prinze = True              neg : pos    =      7.0 : 1.0\n",
            "              schumacher = True              neg : pos    =      7.0 : 1.0\n",
            "                 idiotic = True              neg : pos    =      6.8 : 1.0\n",
            "                   anger = True              pos : neg    =      6.7 : 1.0\n",
            "             wonderfully = True              pos : neg    =      6.5 : 1.0\n",
            "                  wasted = True              neg : pos    =      6.1 : 1.0\n",
            "                   jolie = True              neg : pos    =      5.8 : 1.0\n",
            "                lebowski = True              pos : neg    =      5.6 : 1.0\n",
            "                   flynt = True              pos : neg    =      5.6 : 1.0\n",
            "                   damon = True              pos : neg    =      5.6 : 1.0\n",
            "                    lame = True              neg : pos    =      5.3 : 1.0\n",
            "                   inept = True              neg : pos    =      5.3 : 1.0\n",
            "                   waste = True              neg : pos    =      5.1 : 1.0\n",
            "                   awful = True              neg : pos    =      4.9 : 1.0\n",
            "                  random = True              neg : pos    =      4.9 : 1.0\n",
            "                 breasts = True              neg : pos    =      4.9 : 1.0\n",
            "                  poorly = True              neg : pos    =      4.8 : 1.0\n",
            "              ridiculous = True              neg : pos    =      4.8 : 1.0\n",
            "           uninteresting = True              neg : pos    =      4.7 : 1.0\n",
            "                ordinary = True              pos : neg    =      4.7 : 1.0\n",
            "              henstridge = True              neg : pos    =      4.6 : 1.0\n",
            "                     era = True              pos : neg    =      4.5 : 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzBQIDbH04be",
        "outputId": "627e45d8-bac2-4356-f450-edb3ee6ae1bb"
      },
      "source": [
        "#Logistic Regression Classifier\n",
        "LR_classifier = SklearnClassifier(LogisticRegression())\n",
        "LR_classifier.train(training)\n",
        "print(\"LR_classifier accuracy:\", nltk.classify.accuracy(LR_classifier, testing))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LR_classifier accuracy: 0.86\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aA1koNn04bi",
        "outputId": "094796a4-f9ed-4032-85d4-adb4f0e18f8c"
      },
      "source": [
        "#SVC Classifier\n",
        "SVC_classifier = SklearnClassifier(SVC())\n",
        "SVC_classifier.train(training)\n",
        "print(\"SVC_classifier accuracy: \", nltk.classify.accuracy(SVC_classifier, testing))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVC_classifier accuracy:  0.775\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGZxQ6Zh04bl",
        "outputId": "c30510e1-1c14-4cc5-da7e-d74cdfe64634"
      },
      "source": [
        "#Linear SVC Classifer\n",
        "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
        "LinearSVC_classifier.train(training)\n",
        "print(\"LinearSVC_classifier accuracy:\", nltk.classify.accuracy(LinearSVC_classifier, testing))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LinearSVC_classifier accuracy: 0.835\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfdGVkr704bp",
        "outputId": "f000bd57-eefa-4576-f82a-1f81aa56efef"
      },
      "source": [
        "# Decision Tree Classifier\n",
        "DT_classifier = SklearnClassifier(DecisionTreeClassifier())\n",
        "DT_classifier.train(training)\n",
        "print(\"DT_classifier accuracy:\", nltk.classify.accuracy(DT_classifier, testing))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DT_classifier accuracy: 0.695\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2KDCFpo04bt",
        "outputId": "a6621e2d-0094-4615-ca36-f24cab42bb85"
      },
      "source": [
        "#Decision tree with maximum depth 3\n",
        "DT_classifier2 = SklearnClassifier(DecisionTreeClassifier(max_depth= 3))\n",
        "DT_classifier2.train(training)\n",
        "print(\"DT_classifier2 accuracy:\", nltk.classify.accuracy(DT_classifier2, testing))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DT_classifier2 accuracy: 0.66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXnt9gNn04bx"
      },
      "source": [
        "###### The accuracy is not increasing greatly and also the most important features for nbclassifier have quite a few proper nouns, this classifier won't generalize efficiently. Thus, not making changes to accuracy table for movie_reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Bscvm-704by",
        "outputId": "8a163648-a5fa-4e34-bfe2-0a08c631ddf3"
      },
      "source": [
        "print(\"Accuracy Table for movie_reviews Data\")\n",
        "accuracy_table"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Table for movie_reviews Data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style>\n",
              "    .dataframe thead tr:only-child th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Datasets</th>\n",
              "      <th>Naive Bayes</th>\n",
              "      <th>SVM</th>\n",
              "      <th>Decision Tree</th>\n",
              "      <th>Logistic Regression</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>movie_reviews</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Datasets  Naive Bayes  SVM  Decision Tree  Logistic Regression\n",
              "0  movie_reviews         0.82  0.8           0.69                  0.8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCHxnaLd04b1"
      },
      "source": [
        "# Twitter Samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8Z8MQ1N04b2"
      },
      "source": [
        "from nltk.corpus import twitter_samples as ts \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKOgfbK504b6"
      },
      "source": [
        "#Processing and storing tweets\n",
        "tweets = ts.tokenized()\n",
        "tweets = tweets[:10000]\n",
        "\n",
        "neg_tweets = tweets[:5000]\n",
        "pos_tweets = tweets[5000:]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkIcmBc804b-"
      },
      "source": [
        "###### Following same procedure as done with movie_reviews to create features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bS5YxIt04b-"
      },
      "source": [
        "all_words = []\n",
        "\n",
        "for i in range(len(tweets)-1):\n",
        "    for j in range(len(tweets[i])-1):\n",
        "        all_words.append(tweets[i][j])\n",
        "\n",
        "all_words = set(all_words)\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "punct = set(['.','!','(',')','[',']','{','}','<','>',':',';', '-', ',','\\'','\"'\n",
        "             , '?'])\n",
        "\n",
        "stop_words = stop_words.union(punct)\n",
        "stop_words = list(stop_words)\n",
        "all_words = [w for w in all_words if not w in stop_words]\n",
        "\n",
        "all_words1 = nltk.FreqDist(all_words)\n",
        "\n",
        "word_features = list(all_words1.keys())[:3000]\n",
        "\n",
        "\n",
        "def find_features(tweet):\n",
        "    words = set(tweet)\n",
        "    features = {}\n",
        "    for w in word_features:\n",
        "        features[w] = (w in words)\n",
        "    return features\n",
        "\n",
        "featuresets = [(find_features(tweet), 'neg') for tweet in neg_tweets]\n",
        "\n",
        "for i in range(len(pos_tweets)):\n",
        "    featuresets.append((find_features(pos_tweets[i]), 'pos'))\n",
        "\n",
        "random.shuffle(featuresets)\n",
        "\n",
        "training = featuresets[:7000]\n",
        "testing = featuresets[7000:]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-m1UFoM04cC",
        "outputId": "91c6d5ce-7682-4200-824d-44dafde064d8"
      },
      "source": [
        "#Naive Bayes Classifier\n",
        "nbclassifier = nltk.NaiveBayesClassifier.train(training)\n",
        "print(\"Naive Bayes Classifier Accuracy: \", nltk.classify.accuracy(nbclassifier, testing))\n",
        "nbclassifier.show_most_informative_features(10)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naive Bayes Classifier Accuracy:  0.6446666666666667\n",
            "Most Informative Features\n",
            "                 arrived = True              pos : neg    =     13.6 : 1.0\n",
            "               community = True              pos : neg    =     13.0 : 1.0\n",
            "           @justinbieber = True              neg : pos    =     11.4 : 1.0\n",
            "                     via = True              pos : neg    =     11.4 : 1.0\n",
            "              bestfriend = True              pos : neg    =      9.6 : 1.0\n",
            "                   great = True              pos : neg    =      8.7 : 1.0\n",
            "                    damn = True              neg : pos    =      8.3 : 1.0\n",
            "                    Glad = True              pos : neg    =      7.7 : 1.0\n",
            "                   tired = True              neg : pos    =      6.8 : 1.0\n",
            "                    WANT = True              neg : pos    =      6.3 : 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK6GgfVe04cG",
        "outputId": "c2b2e72a-f984-470a-b219-fd2aedc67e04"
      },
      "source": [
        "#Logistic Regression Classifier\n",
        "LR_classifier = SklearnClassifier(LogisticRegression())\n",
        "LR_classifier.train(training)\n",
        "print(\"LR_classifier accuracy:\", nltk.classify.accuracy(LR_classifier, testing))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LR_classifier accuracy: 0.645\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbN-8FgA04cK",
        "outputId": "cc12070a-8899-4711-c4cd-e02d88f0297b"
      },
      "source": [
        "#SVC Classifier\n",
        "SVC_classifier = SklearnClassifier(SVC())\n",
        "SVC_classifier.train(training)\n",
        "print(\"SVC_classifier accuracy: \", nltk.classify.accuracy(SVC_classifier, testing))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVC_classifier accuracy:  0.49933333333333335\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdlmr3dK04cN",
        "outputId": "998d90a2-303a-47b4-f8f2-3dc7692d4504"
      },
      "source": [
        "#Decision Tree Classifier\n",
        "DT_classifier = SklearnClassifier(DecisionTreeClassifier())\n",
        "DT_classifier.train(training)\n",
        "print(\"DT_classifier accuracy:\", nltk.classify.accuracy(DT_classifier, testing))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DT_classifier accuracy: 0.6403333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dx88-vld04cR"
      },
      "source": [
        "###### Accuracies look pretty bad for classifiers trained on first 3000 words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMrM7KMx04cR"
      },
      "source": [
        "### Trying to improve accuracy of model on twitter_dataset by training on 3000 most common words in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LrHx7Qq04cS"
      },
      "source": [
        "#Following same procedure as done with movie_reviews to create features\n",
        "\n",
        "all_words = []\n",
        "\n",
        "for i in range(len(tweets)-1):\n",
        "    for j in range(len(tweets[i])-1):\n",
        "        all_words.append(tweets[i][j])\n",
        "\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "punct = set(['.','!','(',')','[',']','{','}','<','>',':',';', '-', ',','\\'','\"'\n",
        "             , '?'])\n",
        "\n",
        "stop_words = stop_words.union(punct)\n",
        "stop_words = list(stop_words)\n",
        "all_words = [w for w in all_words if not w in stop_words]\n",
        "\n",
        "all_words1 = nltk.FreqDist(all_words)\n",
        "\n",
        "word_features = all_words1.most_common(3000)\n",
        "word_features = [word_features[i][0] for i in range(len(word_features))]\n",
        "\n",
        "def find_features(tweet):\n",
        "    words = set(tweet)\n",
        "    features = {}\n",
        "    for w in word_features:\n",
        "        features[w] = (w in words)\n",
        "    return features\n",
        "\n",
        "featuresets = [(find_features(tweet), 'neg') for tweet in neg_tweets]\n",
        "\n",
        "for i in range(len(pos_tweets)):\n",
        "    featuresets.append((find_features(pos_tweets[i]), 'pos'))\n",
        "\n",
        "random.shuffle(featuresets)\n",
        "\n",
        "training = featuresets[:7000]\n",
        "testing = featuresets[7000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_EeohMS04cY",
        "outputId": "78565e82-5c7a-40ff-9f7c-6462328f21bb"
      },
      "source": [
        "#Naive Bayes Classifier\n",
        "nbclassifier = nltk.NaiveBayesClassifier.train(training)\n",
        "acc1 = nltk.classify.accuracy(nbclassifier, testing)\n",
        "print(\"Naive Bayes Classifier Accuracy: \", acc1)\n",
        "nbclassifier.show_most_informative_features(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naive Bayes Classifier Accuracy:  0.9966666666666667\n",
            "Most Informative Features\n",
            "                      :( = True              neg : pos    =   2078.1 : 1.0\n",
            "                      :) = True              pos : neg    =   1641.7 : 1.0\n",
            "                     sad = True              neg : pos    =     29.9 : 1.0\n",
            "                     See = True              pos : neg    =     29.8 : 1.0\n",
            "                    miss = True              neg : pos    =     28.8 : 1.0\n",
            "                  THANKS = True              neg : pos    =     24.1 : 1.0\n",
            "                  FOLLOW = True              neg : pos    =     22.7 : 1.0\n",
            "                   Thank = True              pos : neg    =     22.2 : 1.0\n",
            "                 arrived = True              pos : neg    =     19.8 : 1.0\n",
            "                     x15 = True              neg : pos    =     19.3 : 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZM_34GbU04ce",
        "outputId": "07a82ee2-be7d-4eea-f5c0-680e5f6046ba"
      },
      "source": [
        "nbclassifier.show_most_informative_features(50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most Informative Features\n",
            "                      :( = True              neg : pos    =   2078.1 : 1.0\n",
            "                      :) = True              pos : neg    =   1641.7 : 1.0\n",
            "                     sad = True              neg : pos    =     29.9 : 1.0\n",
            "                     See = True              pos : neg    =     29.8 : 1.0\n",
            "                    miss = True              neg : pos    =     28.8 : 1.0\n",
            "                  THANKS = True              neg : pos    =     24.1 : 1.0\n",
            "                  FOLLOW = True              neg : pos    =     22.7 : 1.0\n",
            "                   Thank = True              pos : neg    =     22.2 : 1.0\n",
            "                 arrived = True              pos : neg    =     19.8 : 1.0\n",
            "                     x15 = True              neg : pos    =     19.3 : 1.0\n",
            "                  Thanks = True              pos : neg    =     17.2 : 1.0\n",
            "                 welcome = True              pos : neg    =     15.5 : 1.0\n",
            "                   loves = True              pos : neg    =     15.5 : 1.0\n",
            "               followers = True              pos : neg    =     15.4 : 1.0\n",
            "                     TOO = True              neg : pos    =     15.3 : 1.0\n",
            "                  thanks = True              pos : neg    =     15.0 : 1.0\n",
            "                    lost = True              neg : pos    =     14.6 : 1.0\n",
            "                   Enjoy = True              pos : neg    =     12.8 : 1.0\n",
            "               wonderful = True              pos : neg    =     12.8 : 1.0\n",
            "                       😭 = True              neg : pos    =     12.6 : 1.0\n",
            "                    Love = True              pos : neg    =     11.5 : 1.0\n",
            "                    glad = True              pos : neg    =     11.5 : 1.0\n",
            "                 missing = True              neg : pos    =     11.2 : 1.0\n",
            "                      ME = True              neg : pos    =     11.1 : 1.0\n",
            "                   sorry = True              neg : pos    =     10.9 : 1.0\n",
            "              bestfriend = True              pos : neg    =     10.8 : 1.0\n",
            "               community = True              pos : neg    =     10.8 : 1.0\n",
            "                  online = True              neg : pos    =     10.5 : 1.0\n",
            "                   hurts = True              neg : pos    =     10.5 : 1.0\n",
            "                   enjoy = True              pos : neg    =      9.6 : 1.0\n",
            "                    Have = True              pos : neg    =      9.6 : 1.0\n",
            "               goodnight = True              pos : neg    =      9.5 : 1.0\n",
            "                 perfect = True              pos : neg    =      9.5 : 1.0\n",
            "                    MUCH = True              neg : pos    =      9.5 : 1.0\n",
            "           @justinbieber = True              neg : pos    =      9.3 : 1.0\n",
            "                     Let = True              pos : neg    =      9.2 : 1.0\n",
            "                  PLEASE = True              neg : pos    =      9.2 : 1.0\n",
            "                      rn = True              neg : pos    =      9.2 : 1.0\n",
            "                   Great = True              pos : neg    =      8.8 : 1.0\n",
            "                  Friday = True              pos : neg    =      8.7 : 1.0\n",
            "                   great = True              pos : neg    =      8.7 : 1.0\n",
            "                      :( = False             pos : neg    =      8.5 : 1.0\n",
            "                   Still = True              neg : pos    =      8.5 : 1.0\n",
            "                   tired = True              neg : pos    =      8.3 : 1.0\n",
            "                    Glad = True              pos : neg    =      8.2 : 1.0\n",
            "              definitely = True              pos : neg    =      8.2 : 1.0\n",
            "                    cold = True              neg : pos    =      7.8 : 1.0\n",
            "                   alone = True              neg : pos    =      7.8 : 1.0\n",
            "                     via = True              pos : neg    =      7.8 : 1.0\n",
            "                  You're = True              pos : neg    =      7.7 : 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y81WiP0Q04ci",
        "outputId": "9dd6ba33-d747-4928-dbfd-193bd4be67d4"
      },
      "source": [
        "#Logistic Regression Classifier\n",
        "LR_classifier = SklearnClassifier(LogisticRegression())\n",
        "LR_classifier.train(training)\n",
        "acc2 = nltk.classify.accuracy(LR_classifier, testing)\n",
        "print(\"LR_classifier accuracy:\", acc2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LR_classifier accuracy: 0.996\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcX3AjBn04cm",
        "outputId": "3059496d-35dd-4048-ae2c-1674a2b58a1a"
      },
      "source": [
        "#SVC Classifier\n",
        "SVC_classifier = SklearnClassifier(SVC())\n",
        "SVC_classifier.train(training)\n",
        "acc3 = nltk.classify.accuracy(SVC_classifier, testing)\n",
        "print(\"SVC_classifier accuracy: \", acc3)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVC_classifier accuracy:  0.9896666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhZUWAzy04cr",
        "outputId": "46cf886b-7b99-41f6-b429-f83751775451"
      },
      "source": [
        "#Decision Tree Classifier\n",
        "DT_classifier = SklearnClassifier(DecisionTreeClassifier())\n",
        "DT_classifier.train(training)\n",
        "acc4 = nltk.classify.accuracy(DT_classifier, testing)\n",
        "print(\"DT_classifier accuracy:\", acc4 )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DT_classifier accuracy: 0.995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "repoqGGL04cw"
      },
      "source": [
        "acc_tab = {'Datasets' : 'twitter_dataset',\n",
        "                'Naive Bayes': acc1,\n",
        "                'SVM': acc3,\n",
        "                'Decision Tree': acc4,\n",
        "                'Logistic Regression': acc2}\n",
        "\n",
        "acc_tab = pd.DataFrame([acc_tab], columns=acc_tab.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsHvZyBj04c0"
      },
      "source": [
        "# Final Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCjD04Il04c1",
        "outputId": "126dff71-f83f-4a1f-f071-7090956deb34"
      },
      "source": [
        "print(\"Accuracy table for movie_reviews data\")\n",
        "accuracy_table"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy table for movie_reviews data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style>\n",
              "    .dataframe thead tr:only-child th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Datasets</th>\n",
              "      <th>Naive Bayes</th>\n",
              "      <th>SVM</th>\n",
              "      <th>Decision Tree</th>\n",
              "      <th>Logistic Regression</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>movie_reviews</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Datasets  Naive Bayes  SVM  Decision Tree  Logistic Regression\n",
              "0  movie_reviews         0.82  0.8           0.69                  0.8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E40CZ7n04c4",
        "outputId": "968a5eca-d19f-4a52-8ac1-7a57e16679f9"
      },
      "source": [
        "print(\"Accuracy table for twitter_samples data\")\n",
        "acc_tab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy table for twitter_samples data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style>\n",
              "    .dataframe thead tr:only-child th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Datasets</th>\n",
              "      <th>Naive Bayes</th>\n",
              "      <th>SVM</th>\n",
              "      <th>Decision Tree</th>\n",
              "      <th>Logistic Regression</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>twitter_dataset</td>\n",
              "      <td>0.996667</td>\n",
              "      <td>0.989667</td>\n",
              "      <td>0.995</td>\n",
              "      <td>0.996</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Datasets  Naive Bayes       SVM  Decision Tree  Logistic Regression\n",
              "0  twitter_dataset     0.996667  0.989667          0.995                0.996"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4usfff4k04c8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}